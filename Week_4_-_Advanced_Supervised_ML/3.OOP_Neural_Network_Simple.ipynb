{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "#  Neural Network Linear Regression: Simple approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "This Jupyter Notebook trains a very simple neural network model to perform Linear Regression. We will use the NESA Course Specifications Linear Regression dataset, which students are already familiar with so, they can focus on understanding the TensorFlow OOP Neural Network implementation.\n",
        "\n",
        "#### Course Specifications\n",
        "\n",
        "<figure>\n",
        "    <center><img src=\"images\\NN_Course-Specs.png\" alt=\"Course Specs Neural Network image\" width=\"500\" />\n",
        "    <figcaption><p><em>Source: Page 29 of the Software Engineering Course Specifications</em></p>\n",
        "    </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Neural networks were designed to mimic the processing inside the human brain. They consist of a series of interconnected nodes (artificial neurones). Each neurone can accept a binary input signal and potentially output another signal to connected nodes.\n",
        "\n",
        "In the diagram, signal strength between nodes with the strongest weightings are thicker representing a higher priority in determining the final output. The 'Bias' and 'Weightings' are learnt during the training cycle and used for predictions in the execution cycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1 - Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error \n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "#### Step 2: Import The Data\n",
        "We will extended the dataset, to allow for test/training splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [],
      "source": [
        "#Import data as a numPy array\n",
        "# Training features\n",
        "X_feature = np.array([[-26], [-24], [-22], [-20], [-18], [-16], [-14], [-12], [-10], [-8], [-6], [-4], [-2], [0], [2], [4], [6], [8], [10], [12], [14], [16], [18], [20], [22], [24], [26]])\n",
        "\n",
        "# Target variable\n",
        "y_target = np.array([-27, -25, -23, -21, -19, -17, -15, -13, -11, -9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Split The Data into Training And Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_feature, y_target, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Visualise The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "outputs": [],
      "source": [
        "# Plot the training and test data\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axs[0].scatter(X_train, y_train, s=40)\n",
        "axs[0].set_title(\"Training Data\")\n",
        "axs[0].set_xlabel(\"X\")\n",
        "axs[0].set_ylabel(\"y\")\n",
        "\n",
        "\n",
        "axs[1].scatter(X_test, y_test, s=40)\n",
        "axs[1].set_title(\"Test Data\")\n",
        "axs[1].set_xlabel(\"X\")\n",
        "axs[1].set_ylabel(\"y\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "#### Step 5: Instantiate a Neural Network Object And Configure The Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "The basic building block of a neural network is the [*layer*](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
        "\n",
        "Most of deep learning consists of chaining together simple layers. Most layers, such as `tf.keras.layers.Dense`, have parameters that are learned during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(1,)),  # Input layer with 1 feature\n",
        "    Dense(3, activation='relu'),           # Hidden layer with 3 neurons\n",
        "    Dense(1)            # Output layer with 1 neuron for regression\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### About this model\n",
        "\n",
        "The above code will instantiate a model (lines 1-5) with an input layer (line 2) that, in this case, will have 1 neuron and take in an array of features. The model then has a hidden layer with 3 neurons (line 3). The model then has an output layer with 1 neuron (line 4) that will output a regression value. In training, the input data will be passed forward and backward in training cycles to find the optimal settings (see epochs below).\n",
        "\n",
        "> [!Note]\n",
        ">\n",
        "> The output layer should have 2 neurons for binary classification or $n$ neurons for the $n$ classes in multiclass classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "#### Step 6: Fit The Model\n",
        "\n",
        "Fitting (Training) the neural network model requires the following steps:\n",
        "\n",
        "1. Fit the training data to the model. In this example, the training data is in the `X_train` and `y_train` arrays.\n",
        "2. The model learns to associate features and targets.\n",
        "3. You ask the model to make predictions about a test setâ€”in this example, the `X_test`.\n",
        "4. Verify that the predictions match the targets from the `y_ array` array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvwvpA64CaW_"
      },
      "outputs": [],
      "source": [
        "# You can adjust the number of epochs and batch size based on your data and resources.\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training Cycle \n",
        "\n",
        "An $Epoch$ represents one complete training cycle of a neural network. During each $Epoch$, the network processes the entire training dataset once, adjusting its internal weights and biases. Initially, these weights and biases are set to random values. Using the training data (inputs with known outputs), the network applies forward propagation to make predictions and backward propagation to iteratively update the weights. This process minimises the error between predicted and actual outputs. With repeated epochs, the network's accuracy improves as it learns to recognise patterns in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### Step 8: Execution Cycle (Make predictions)\n",
        "\n",
        "The execution cycle follows the training cycle and utilises the optimal internal values developed during the training cycle to determine the output. With the model trained, you can use it to make predictions about new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnfNA0CrQLSD"
      },
      "outputs": [],
      "source": [
        "#Predict the target for a new data point\n",
        "new_y = np.array([4])\n",
        "\n",
        "new_y = model.predict(new_y)\n",
        "print(f\"New feature is:\\n{new_y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> [!Important]\n",
        ">\n",
        "> Neural Network training is inherently [stochastic](https://en.wikipedia.org/wiki/Stochastic), the tuning of the neurons depends on the initialisation of the weights. So the result (the local minimum you end up in) depends on the initialisation too. This can be observed in the variance of this prediction after re-training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9yABaME29S"
      },
      "source": [
        "#### Step 9: Plot the Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "outputs": [],
      "source": [
        "# Plot the actual data and model predictions\n",
        "plt.scatter(X_train, y_train, label='Training Data', color='blue')\n",
        "plt.scatter(X_train, model.predict(y_train), label='Predicted Training Data', color='red')\n",
        "plt.scatter(X_test, y_test, label='Testing Data', color='green')\n",
        "plt.scatter(X_test, model.predict(y_test), label='Predicted Testing Data', color='yellow')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.title('Neural Network Regression')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 9: Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get Evalutative Data from the model\n",
        "model_eval = model.evaluate(X_test, y_test)\n",
        "print(f\"Model Evalutation: {model_eval}\")\n",
        "mae = mean_absolute_error(y_true=y_train,y_pred=model.predict(y_train)) \n",
        "mse = mean_squared_error(y_true=y_train,y_pred=model.predict(y_train))\n",
        "print(\"MAE:\",mae) \n",
        "print(\"MSE:\",mse) \n",
        "print()\n",
        "\n",
        "#Manually calculate the loss and cost of the model\n",
        "predictions = model.predict(y_train).flatten()\n",
        "model_loss = pd.DataFrame({\n",
        "    'Target': y_train,\n",
        "    'Predicted result': predictions,\n",
        "    'Loss': abs(y_train - predictions)\n",
        "})\n",
        "model_cost = (1/model_loss.shape[0]) * (model_loss['Loss'].sum() / model_loss.shape[0])\n",
        "print(f\"The cost or average loss of this model is {model_cost:.5f}\")\n",
        "print(model_loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
