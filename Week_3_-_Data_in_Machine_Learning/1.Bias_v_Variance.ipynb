{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bias versus Model Variance\n",
    "\n",
    "| Signs of Bias | Signs of Variance |\n",
    "| --- | --- |\n",
    "| Poor or inconsistent intuition | Poor intuition with new & testing data |\n",
    "| Poor intuition with Training data | Noise in data set |\n",
    "| Poor intuition compared to similar models | Overfitting |\n",
    "| Underfitting | Complexity |\n",
    "| Simplicity | High MSE |\n",
    "\n",
    "Model Bias â‰  ML/AI Bias, they are different concepts, Model Bias is about relisation error.\n",
    "\n",
    "| Term | Definition |\n",
    "| --- | --- |\n",
    "| Generalisation | A model that generalizes well can make accurate predictions or classifications on data it wasn't trained on | \n",
    "| Bias | Bias represents the difference between the average prediction and the true value |\n",
    "| Variance | Variance measures the variability or inconsistency of predictions made by a model when trained on different subsets of the same data. It reflects how much the model's predictions change if the training data is shuffled or split differently.  |\n",
    "| Noise | Random or irrelevant data points or variations that obscure meaningful patterns and can negatively impact the accuracy of analysis or machine learning models |\n",
    "\n",
    "The bias-variance tradeoff in machine learning refers to the fundamental relationship between a model's ability to fit the training data (bias) and its ability to generalize to new, unseen data (variance). It's a balancing act where reducing bias often increases variance, and vice versa. The goal is to find the optimal model complexity that minimizes overall error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_common import compute_model_output, generate_data, compute_model_output\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good Fit/Intuition with low bias and low variance\n",
    "o = np.sort(generate_data(-10, 10, -10, 10, 8, 0.2))\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "ax[0].scatter(o[0], o[1], color='blue', s=100)\n",
    "ax[0].plot(o[0], o[1], color='red')\n",
    "x = np.linspace(10, -10, 100)\n",
    "y = -x**2 + 4*x + 2  \n",
    "ax[2].plot(x, y, color='red')\n",
    "x = x + np.random.uniform(-5, 5, size=x.shape)\n",
    "y = y + np.random.uniform(-10, 10, size=y.shape)\n",
    "ax[1].scatter(x, y, c='b')\n",
    "ax[2].scatter(x, y, c='b')\n",
    "x_lin = np.array([-10,10])\n",
    "tmp_f_mb = compute_model_output(x_lin, 10, -10,)\n",
    "ax[1].plot(x_lin, tmp_f_mb, c='r')\n",
    "ax[0].title.set_text(\"High Variance/Overfitting\")\n",
    "ax[1].title.set_text(\"High Bias/Underfitting\")\n",
    "ax[2].title.set_text(\"Low Bias and Low Variance/Good Fit\")\n",
    "for ax in ax.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between Bias, Variance and Generalisation (Fit/Intuition)\n",
    "\n",
    "##### 1. High Variance (Overfitting):\n",
    "\n",
    "A model with high variance is too complex and learns the training data too well, including the noise.\n",
    "\n",
    "__Example__: Using a very high-degree polynomial regression model on a relatively small dataset.\n",
    "\n",
    "__Consequences__: Excellent performance on the training data but poor performance on new data, as the model has memorized the training set instead of learning the underlying patterns.\n",
    "\n",
    "##### 2. High Bias (Underfitting):\n",
    "\n",
    "A model with high bias is too simple and doesn't capture the underlying patterns in the data.\n",
    "\n",
    "__Example__: Using a linear regression model to fit highly non-linear data.\n",
    "\n",
    "__Consequences__: Poor performance on both training and test data, as the model is unable to represent the true relationship.\n",
    "\n",
    "\n",
    "##### 3. Low Variance / Low Bias (Good Fit or Intution):\n",
    "\n",
    "The model is complex enough to capture the underlying patterns but not so complex that it overfits to the noise in the training data. The model should perform equally well with the training data and new/unseen data such as testing data or real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inconsistent Fit/Intuition\n",
    "\n",
    "Solutions ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = generate_data(25, 50, 25, 50, 100, 0.9)\n",
    "n = generate_data(0, 50, 0, 50, 10, 0.01)\n",
    "w = 1\n",
    "b = -1\n",
    "\n",
    "tmp_f_wb = compute_model_output(np.concatenate([m[0], n[0]]), w, b,)\n",
    "plt.plot(np.concatenate([m[0], n[0]]), tmp_f_wb, c='r', label=f'Prediction: y = {w}x + {b}' )\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(m[0], m[1], color='blue')\n",
    "plt.scatter(n[0], n[1], color='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
